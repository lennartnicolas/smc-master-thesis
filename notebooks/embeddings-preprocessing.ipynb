{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3cf8ccb",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "This notebooks merges the computed YAMNET Embeddings with other metadata like user tags, title and hierarchical labels of the FSD50K annotations (ground truth labels). Further we translate the class names to their corresponding ontology IDs to avoid comparison problems of different string (text) representations. The computed embeddings are saved in json format for each audiofile with three keys: main class label, class probabilities and the 1024 sized feature vector. From 10231 files of the evaluation set, 9093 embeddings were computed succesfully while 1138 were null embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f68c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf91c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAMNET Embeddings for FSD50K evaluation set: original size (10231), embeddings size (9093), null embeddings (1138)\n",
    "# Specify paths for all necessary files\n",
    "DATA_DIR          = 'data'\n",
    "EMB_DIR           = os.path.join(DATA_DIR, 'yamnet-embeddings-eval')\n",
    "FSD50K_EVAL_CLIPS = os.path.join(DATA_DIR, 'eval_clips_info_FSD50K.json')\n",
    "EVAL_HLABELS      = os.path.join(DATA_DIR, 'eval.csv')\n",
    "ONTOLOGY_JSON     = os.path.join(DATA_DIR, 'ontology.json')\n",
    "FSD50K_VOCABULARY = os.path.join(DATA_DIR, 'vocabulary.csv')\n",
    "OUTPUT_FILE       = os.path.join(DATA_DIR, 'eval_clips_info_FSD50K_analysis.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82f9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output dictionary\n",
    "output_dict = {}\n",
    "\n",
    "# Ontology translation\n",
    "onto_df         = pd.read_json(ONTOLOGY_JSON)\n",
    "fsdk_df         = pd.read_csv(FSD50K_VOCABULARY, header=None)\n",
    "fsdk_name_to_id = dict(zip(fsdk_df[1], fsdk_df[2]))\n",
    "onto_name_to_id = dict(zip(onto_df['name'], onto_df['id']))\n",
    "fsdk_id_to_name = dict(zip(fsdk_df[2], fsdk_df[1]))\n",
    "onto_id_to_name = dict(zip(onto_df['id'], onto_df['name']))\n",
    "\n",
    "# Open evaluation set\n",
    "with open(FSD50K_EVAL_CLIPS , 'r') as f:\n",
    "    fsd50k_dict = json.load(f)\n",
    "\n",
    "# Subset of files for better distribution of data\n",
    "all_files = np.load('all_files_ids.npy')\n",
    "\n",
    "# Iterate over embeddings jsons\n",
    "for f in os.listdir(EMB_DIR):\n",
    "    \n",
    "    # Skip dotfiles etc.\n",
    "    if f.startswith('.') or not os.path.isfile(os.path.join(EMB_DIR, f)): continue\n",
    "    \n",
    "    # File ID\n",
    "    f_id = f.split('-')[0]  \n",
    "    \n",
    "    if str(f_id + '.wav') in all_files:\n",
    "        # Open JSON\n",
    "        with open(os.path.join(EMB_DIR, f)) as jf:\n",
    "            emb_json = json.load(jf)\n",
    "    \n",
    "        # Embeddings data\n",
    "        emb_class    = str(emb_json['classes'][0])\n",
    "        prob_classes = emb_json['top_25_classes_probabilities']\n",
    "        embedding    = emb_json['embeddings']\n",
    "        # FSD50K metadata\n",
    "        title        = fsd50k_dict[f_id]['title']\n",
    "        user_tags    = fsd50k_dict[f_id]['tags']\n",
    "        # IDs translation\n",
    "        emb_class_id = onto_name_to_id[emb_class]\n",
    "        # Save data in temporary dict\n",
    "        temp_dict = {} \n",
    "        temp_dict['title']               = title\n",
    "        temp_dict['user_tags']           = user_tags\n",
    "        temp_dict['yamnet_class']        = emb_class\n",
    "        temp_dict['yamnet_class_id']     = emb_class_id\n",
    "        temp_dict['yamnet_prob_classes'] = prob_classes\n",
    "        temp_dict['yamnet_embedding']    = embedding\n",
    "        \n",
    "        # Write data to output dictionary with filename as ID\n",
    "        output_dict[f_id] = temp_dict\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "# Save to JSON  \n",
    "with open(OUTPUT_FILE, 'w') as outfile:\n",
    "    json.dump(output_dict, outfile)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dedf313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
