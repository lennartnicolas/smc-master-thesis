{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d28ab3",
   "metadata": {},
   "source": [
    "### Class refinement and dimensionality reduction\n",
    "This notebooks refines the computed embeddings classes with respect to the hierarchical label annotations of the FSD50K dataset. Further it uses the probability classes and the user tags to find the correct class when hierarchy and embeddings labels are unambiguous. Then the dataset is deduced to an evenly distributed dataset for simplicity. After that, UMAP is applied to reduce the dimension (x/y positions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fc820",
   "metadata": {},
   "source": [
    "#### Class refinement\n",
    "The following cells refine the sound classes based on user tags, embedding labels and probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b114e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pacmap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "import random\n",
    "import enchant\n",
    "from treelib import Tree, Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe7140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify paths for metadata\n",
    "DATA_DIR          = 'data'\n",
    "YAMNET_FILE       = os.path.join(DATA_DIR, 'eval_clips_info_FSD50K_analysis.json')\n",
    "ONTOLOGY_JSON     = os.path.join(DATA_DIR, 'ontology.json')\n",
    "FSD50K_VOCABULARY = os.path.join(DATA_DIR, 'vocabulary.csv')\n",
    "ONTOLOGY_TREE_L1  = os.path.join(DATA_DIR, 'ontology_layer_1.csv')\n",
    "ONTOLOGY_TREE_L2  = os.path.join(DATA_DIR, 'ontology_layer_2.csv')\n",
    "ONTOLOGY_TREE_L3  = os.path.join(DATA_DIR, 'ontology_layer_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5edc22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata JSON\n",
    "yamnet_df = pd.read_json(YAMNET_FILE).T.reset_index().rename(columns={'index': 'file_id'})\n",
    "\n",
    "# Load first two layers of ontology buckets\n",
    "tree_l1_df   = pd.read_csv(ONTOLOGY_TREE_L1, index_col=0).T\n",
    "tree_l2_df   = pd.read_csv(ONTOLOGY_TREE_L2, index_col=0).T\n",
    "tree_l3_df   = pd.read_csv(ONTOLOGY_TREE_L3, index_col=0).T\n",
    "tree_l1_dict = utils.getOntoDict(tree_l1_df)\n",
    "tree_l2_dict = utils.getOntoDict(tree_l2_df)\n",
    "tree_l3_dict = utils.getOntoDict(tree_l3_df)\n",
    "merged_dict  = tree_l1_dict | tree_l2_dict | tree_l3_dict\n",
    "\n",
    "# Ontology translation\n",
    "onto_df         = pd.read_json(ONTOLOGY_JSON)\n",
    "fsdk_df         = pd.read_csv(FSD50K_VOCABULARY, header=None)\n",
    "fsdk_name_to_id = dict(zip(fsdk_df[1], fsdk_df[2]))\n",
    "onto_name_to_id = dict(zip(onto_df['name'], onto_df['id']))\n",
    "fsdk_id_to_name = dict(zip(fsdk_df[2], fsdk_df[1]))\n",
    "onto_id_to_name = dict(zip(onto_df['id'], onto_df['name']))\n",
    "\n",
    "# Ontology layer 1\n",
    "ontology_str = ['Human sounds', 'Source-ambiguous sounds', 'Animal', 'Sounds of things', 'Music', 'Natural sounds', 'Channel, environment and background']\n",
    "ontology_ids = [onto_name_to_id[x] for x in ontology_str]\n",
    "\n",
    "# Save IDs of the 632 ontology classes\n",
    "all_onto_classes_ids = list(set([c_id for c_id in onto_df['id']]) - set(ontology_ids))\n",
    "all_onto_classes     = [onto_id_to_name[c_id] for c_id in all_onto_classes_ids]\n",
    "layer2_classes       = [onto_id_to_name[x] for x in tree_l2_dict.keys()]\n",
    "layer3_classes       = [onto_id_to_name[x] for x in tree_l3_dict.keys()]\n",
    "layer1_2_classes     = np.concatenate((ontology_str, layer2_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed242fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_tags</th>\n",
       "      <th>yamnet_class</th>\n",
       "      <th>yamnet_class_id</th>\n",
       "      <th>yamnet_prob_classes</th>\n",
       "      <th>yamnet_embedding</th>\n",
       "      <th>refined_classes_ids</th>\n",
       "      <th>refined_classes</th>\n",
       "      <th>layer1_id</th>\n",
       "      <th>layer2_id</th>\n",
       "      <th>layer3_id</th>\n",
       "      <th>unrefined_layer1_id</th>\n",
       "      <th>unrefined_layer2_id</th>\n",
       "      <th>unrefined_layer3_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>345138</td>\n",
       "      <td>Closing_Drawer.wav</td>\n",
       "      <td>[drawer, kitchen, close]</td>\n",
       "      <td>Silence</td>\n",
       "      <td>/m/028v0c</td>\n",
       "      <td>[[Silence, 0.7932662367820741], [Inside, small...</td>\n",
       "      <td>[0.677103579044342, 0.23611395061016002, 0.034...</td>\n",
       "      <td>/m/0fqfqc</td>\n",
       "      <td>Drawer open or close</td>\n",
       "      <td>/t/dd00041</td>\n",
       "      <td>/t/dd00071</td>\n",
       "      <td>/m/0fqfqc</td>\n",
       "      <td>/t/dd00098</td>\n",
       "      <td>/m/028v0c</td>\n",
       "      <td>/m/028v0c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>171994</td>\n",
       "      <td>glass1.wav</td>\n",
       "      <td>[glass, light-bulb, breaking]</td>\n",
       "      <td>Glass</td>\n",
       "      <td>/m/039jq</td>\n",
       "      <td>[[Glass, 0.7569197416305541], [Clang, 0.496511...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>/m/07pc8lb</td>\n",
       "      <td>Breaking</td>\n",
       "      <td>/t/dd00098</td>\n",
       "      <td>/t/dd00099</td>\n",
       "      <td>/m/07pc8lb</td>\n",
       "      <td>/t/dd00041</td>\n",
       "      <td>/m/039jq</td>\n",
       "      <td>/m/039jq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840</th>\n",
       "      <td>21314</td>\n",
       "      <td>sound-cough2.wav</td>\n",
       "      <td>[cough, illness, noise]</td>\n",
       "      <td>Cough</td>\n",
       "      <td>/m/01b_21</td>\n",
       "      <td>[[Cough, 0.9605462551116941], [Throat clearing...</td>\n",
       "      <td>[0.0, 0.0, 0.857789754867553, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>/m/01b_21</td>\n",
       "      <td>Cough</td>\n",
       "      <td>/m/0dgw9r</td>\n",
       "      <td>/m/09hlz4</td>\n",
       "      <td>/m/01b_21</td>\n",
       "      <td>/m/0dgw9r</td>\n",
       "      <td>/m/09hlz4</td>\n",
       "      <td>/m/01b_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841</th>\n",
       "      <td>269337</td>\n",
       "      <td>Stirring Ice</td>\n",
       "      <td>[foley, cup, straw, mic, ice, plastic, water, ...</td>\n",
       "      <td>Engine</td>\n",
       "      <td>/m/02mk9</td>\n",
       "      <td>[[Engine, 0.15777900815010001], [Wood, 0.13997...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>/m/02p3nc</td>\n",
       "      <td>Hiccup</td>\n",
       "      <td>/m/0dgw9r</td>\n",
       "      <td>/m/0160x5</td>\n",
       "      <td>/m/02p3nc</td>\n",
       "      <td>/t/dd00041</td>\n",
       "      <td>/m/02mk9</td>\n",
       "      <td>/m/02mk9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6842</th>\n",
       "      <td>207119</td>\n",
       "      <td>Bus.aif</td>\n",
       "      <td>[bus, travel, accelerate, doors]</td>\n",
       "      <td>Vehicle</td>\n",
       "      <td>/m/07yv9</td>\n",
       "      <td>[[Vehicle, 0.6246568560600281], [Helicopter, 0...</td>\n",
       "      <td>[0.00147914304398, 0.000417939940234, 0.040898...</td>\n",
       "      <td>/m/0k4j</td>\n",
       "      <td>Car</td>\n",
       "      <td>/t/dd00041</td>\n",
       "      <td>/m/07yv9</td>\n",
       "      <td>/m/012f08</td>\n",
       "      <td>/t/dd00041</td>\n",
       "      <td>/m/07yv9</td>\n",
       "      <td>/m/07yv9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_id               title  \\\n",
       "6838   345138  Closing_Drawer.wav   \n",
       "6839   171994          glass1.wav   \n",
       "6840    21314    sound-cough2.wav   \n",
       "6841   269337        Stirring Ice   \n",
       "6842   207119             Bus.aif   \n",
       "\n",
       "                                              user_tags yamnet_class  \\\n",
       "6838                           [drawer, kitchen, close]      Silence   \n",
       "6839                      [glass, light-bulb, breaking]        Glass   \n",
       "6840                            [cough, illness, noise]        Cough   \n",
       "6841  [foley, cup, straw, mic, ice, plastic, water, ...       Engine   \n",
       "6842                   [bus, travel, accelerate, doors]      Vehicle   \n",
       "\n",
       "     yamnet_class_id                                yamnet_prob_classes  \\\n",
       "6838       /m/028v0c  [[Silence, 0.7932662367820741], [Inside, small...   \n",
       "6839        /m/039jq  [[Glass, 0.7569197416305541], [Clang, 0.496511...   \n",
       "6840       /m/01b_21  [[Cough, 0.9605462551116941], [Throat clearing...   \n",
       "6841        /m/02mk9  [[Engine, 0.15777900815010001], [Wood, 0.13997...   \n",
       "6842        /m/07yv9  [[Vehicle, 0.6246568560600281], [Helicopter, 0...   \n",
       "\n",
       "                                       yamnet_embedding refined_classes_ids  \\\n",
       "6838  [0.677103579044342, 0.23611395061016002, 0.034...           /m/0fqfqc   \n",
       "6839  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          /m/07pc8lb   \n",
       "6840  [0.0, 0.0, 0.857789754867553, 0.0, 0.0, 0.0, 0...           /m/01b_21   \n",
       "6841  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           /m/02p3nc   \n",
       "6842  [0.00147914304398, 0.000417939940234, 0.040898...             /m/0k4j   \n",
       "\n",
       "           refined_classes   layer1_id   layer2_id   layer3_id  \\\n",
       "6838  Drawer open or close  /t/dd00041  /t/dd00071   /m/0fqfqc   \n",
       "6839              Breaking  /t/dd00098  /t/dd00099  /m/07pc8lb   \n",
       "6840                 Cough   /m/0dgw9r   /m/09hlz4   /m/01b_21   \n",
       "6841                Hiccup   /m/0dgw9r   /m/0160x5   /m/02p3nc   \n",
       "6842                   Car  /t/dd00041    /m/07yv9   /m/012f08   \n",
       "\n",
       "     unrefined_layer1_id unrefined_layer2_id unrefined_layer3_id  \n",
       "6838          /t/dd00098           /m/028v0c           /m/028v0c  \n",
       "6839          /t/dd00041            /m/039jq            /m/039jq  \n",
       "6840           /m/0dgw9r           /m/09hlz4           /m/01b_21  \n",
       "6841          /t/dd00041            /m/02mk9            /m/02mk9  \n",
       "6842          /t/dd00041            /m/07yv9            /m/07yv9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Define some local helper functions\n",
    "'''\n",
    "\n",
    "def getBucketKey(class_id):\n",
    "    # Check for layer 3 and return key\n",
    "    for key, item in tree_l3_dict.items():\n",
    "        if class_id in item:\n",
    "            return key\n",
    "\n",
    "def checkBucketl2(class_id):\n",
    "    # Check for layer 2\n",
    "    for key, item in tree_l2_dict.items():\n",
    "        if class_id in item:\n",
    "            return key\n",
    "    return class_id\n",
    "\n",
    "def checkBucketl3(class_id):\n",
    "    # Check for layer 3 and return id\n",
    "    for key, item in tree_l3_dict.items():\n",
    "        if class_id in item:\n",
    "            return key\n",
    "    return class_id\n",
    "\n",
    "def userTagsDistances(value, bucket=[], flag=False):\n",
    "    # Compute distances between tag and ontology classes\n",
    "    distances = []\n",
    "    b = all_onto_classes\n",
    "    if flag:\n",
    "        b = bucket\n",
    "    for cl in b:\n",
    "        ld = enchant.utils.levenshtein(cl, value)\n",
    "        distances.append(ld)\n",
    "    return distances\n",
    "\n",
    "def refineClass(row):    \n",
    "    '''\n",
    "    The refinement process as described in the thesis paper\n",
    "    returns: class_id\n",
    "    '''\n",
    "    \n",
    "    prob_init    = row['yamnet_prob_classes']\n",
    "    user_tags    = np.array(row['user_tags'])\n",
    "    title        = row['title']\n",
    "    user_data    = np.append(user_tags, title)\n",
    "    prob_classes = []\n",
    "    \n",
    "    \n",
    "    # Remove first and second layer classifications [bad workaround]\n",
    "    for idx, cl in enumerate(prob_init):\n",
    "        if cl[0] not in layer1_2_classes:\n",
    "            prob_classes.append(cl)\n",
    "    \n",
    "    # If the embedding was really sure..\n",
    "    if prob_classes[0][1] > 0.85:\n",
    "        return onto_name_to_id[prob_classes[0][0]]\n",
    "\n",
    "    # Check user tags and title and receive nearest classes\n",
    "    for tag in user_data:\n",
    "        # Simple string comparison\n",
    "        ltag  = tag.lower()\n",
    "        for x in layer3_classes:\n",
    "            if ltag in x.lower():\n",
    "                return onto_name_to_id[x]\n",
    "    \n",
    "    # Iterate over first 10 probability classes to get refined bucket of classes\n",
    "    prob_buckets = []\n",
    "    for c in prob_classes:\n",
    "        class_d  = onto_name_to_id[c[0]]\n",
    "        prob_key = getBucketKey(class_d)\n",
    "        prob_buckets.append(prob_key)        \n",
    "    \n",
    "    # Get nearest class for user tags based on levensthein distance\n",
    "    user_classes = []\n",
    "    buck_key  = getBucketKey([max(prob_buckets,key=prob_buckets.count)])\n",
    "    buck_vals = merged_dict[buck_key]\n",
    "    \n",
    "    for tag in user_data:\n",
    "        distances = userTagsDistances(tag, buck_vals, True)\n",
    "        minValIdx = utils.getMinValIndex(distances)\n",
    "        nearClass = buck_vals[minValIdx]\n",
    "        user_classes.append(nearClass)\n",
    "    \n",
    "    # If refined labels bucket has no majority class, return the parent class\n",
    "    if len(user_classes) == len(set(user_classes)):\n",
    "        return buck_key\n",
    "    else:\n",
    "        return max(user_classes,key=user_classes.count)\n",
    "\n",
    "    \n",
    "# Refine class for each file of the dataframe \n",
    "refined_classes_ids    = []\n",
    "refined_classes        = []\n",
    "refined_parent_id_l1   = []\n",
    "refined_parent_id_l2   = []\n",
    "refined_parent_id_l3   = []\n",
    "unrefined_parent_id_l1 = []\n",
    "unrefined_parent_id_l2 = []\n",
    "unrefined_parent_id_l3 = []\n",
    "for i, row in yamnet_df.iterrows():\n",
    "    \n",
    "    # Refine class\n",
    "    ref_class_id = refineClass(row)\n",
    "    ref_class    = onto_id_to_name[ref_class_id]\n",
    "    refined_classes_ids.append(ref_class_id)\n",
    "    refined_classes.append(ref_class)\n",
    "    \n",
    "    for key, item in tree_l1_dict.items():\n",
    "        if ref_class_id in item:\n",
    "            refined_parent_id_l1.append(key)\n",
    "            break\n",
    "    \n",
    "    for key, item in tree_l2_dict.items():\n",
    "        if ref_class_id in item:\n",
    "            refined_parent_id_l2.append(key)\n",
    "            break\n",
    "    \n",
    "    for key, item in tree_l3_dict.items():\n",
    "        if ref_class_id in item:\n",
    "            refined_parent_id_l3.append(key)\n",
    "            break\n",
    "\n",
    "    # Unrefined layer 1 labels for base model\n",
    "    class_label = row['yamnet_class_id']\n",
    "    \n",
    "    for key, item in tree_l1_dict.items():\n",
    "        if class_label in item:\n",
    "            unrefined_parent_id_l1.append(key)\n",
    "            break\n",
    "    \n",
    "    unrefined_parent_id_l2.append(checkBucketl2(class_label))\n",
    "    unrefined_parent_id_l3.append(checkBucketl3(class_label))\n",
    "              \n",
    "\n",
    "# Put columns in dataframe\n",
    "yamnet_df['refined_classes_ids']   = refined_classes_ids\n",
    "yamnet_df['refined_classes']       = refined_classes\n",
    "yamnet_df['layer1_id']             = refined_parent_id_l1\n",
    "yamnet_df['layer2_id']             = refined_parent_id_l2\n",
    "yamnet_df['layer3_id']             = refined_parent_id_l3\n",
    "yamnet_df['unrefined_layer1_id']   = unrefined_parent_id_l1\n",
    "yamnet_df['unrefined_layer2_id']   = unrefined_parent_id_l2\n",
    "yamnet_df['unrefined_layer3_id']   = unrefined_parent_id_l3\n",
    " \n",
    "yamnet_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a2fdd4",
   "metadata": {},
   "source": [
    "#### UMAP\n",
    "\n",
    "Compute UMAP of embedding and class label (1) with refined labels and (2) without refined labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567a7d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "# For refined labels\n",
    "X      = np.array(list(yamnet_df['yamnet_embedding']))\n",
    "labels = utils.getColormap(list(yamnet_df['layer1_id']))\n",
    "embedding = umap.UMAP(n_neighbors=40, random_state=25).fit_transform(X, y=labels)  \n",
    "yamnet_df['xypos'] = embedding.tolist() \n",
    "# Save to JSON file\n",
    "fname = 'eval_clips_info_FSD50K_analysis_refinement_umap_refined.json'\n",
    "path = os.path.join(DATA_DIR, fname)\n",
    "yamnet_df.to_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0db4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For unrefined labels\n",
    "X      = np.array(list(yamnet_df['yamnet_embedding']))\n",
    "labels = utils.getColormap(list(yamnet_df['unrefined_layer1_id']))\n",
    "embedding = umap.UMAP(n_neighbors=40, random_state=25).fit_transform(X, y=labels)  \n",
    "yamnet_df['xypos'] = embedding.tolist() \n",
    "# Save to JSON file\n",
    "fname = 'eval_clips_info_FSD50K_analysis_refinement_umap_unrefined.json'\n",
    "path = os.path.join(DATA_DIR, fname)\n",
    "yamnet_df.to_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c8eee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
